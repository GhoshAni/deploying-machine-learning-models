{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.models\n",
    "from mlflow.models import infer_signature\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score, precision_score\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    recall = recall_score(y_test, y_pred, average= 'weighted'),\n",
    "    f1 = f1_score(y_test, y_pred, average= 'weighted'),\n",
    "    accuracy = accuracy_score(y_test, y_pred),\n",
    "    precision = precision_score(y_test, y_pred, average= 'weighted')\n",
    "    \n",
    "    return recall, f1, accuracy, precision\n",
    "\n",
    "#average: Literal['micro', 'macro', 'samples', 'weighted', 'binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "  recall:  1.0\n",
      "  f1: 1.0\n",
      "  accuracy:  1.0\n",
      "  precision:  1.0\n",
      "üèÉ View run rumbling-hawk-909 at: http://127.0.0.1:8080/#/experiments/228836478271870438/runs/47e221c458324ec09cb079143af594b2\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/228836478271870438\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    np.random.seed(40)\n",
    "    \n",
    "    try:\n",
    "        iris = load_iris()\n",
    "        X = pd.DataFrame(data = iris.data, columns= iris.feature_names)\n",
    "        y = iris.target\n",
    "        \n",
    "        # Split the data into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "        print(X.shape)\n",
    "         \n",
    "    except Exception as e:\n",
    "        logger.exception(\n",
    "            \"Unable to download training & test CSV, check your internet connection. Error: %s\", e)\n",
    "    \n",
    "    # set tracking server\n",
    "    \n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "    \n",
    "    # create a new experiment\n",
    "\n",
    "    mlflow.set_experiment(\"MLflow_iris\")\n",
    "    \n",
    "    if mlflow.active_run():\n",
    "       mlflow.end_run()\n",
    "    \n",
    "    with mlflow.start_run(nested= True):    \n",
    "    # Define the model hyperparameters\n",
    "        params = {\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"max_iter\": 1000,\n",
    "        \"multi_class\": \"auto\",\n",
    "        \"random_state\": 8888}\n",
    "\n",
    "    # Train the model\n",
    "        lr = LogisticRegression(**params)\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "        y_pred = lr.predict(X_test)\n",
    "\n",
    "    # Eval and log\n",
    "        recall, f1, accuracy, precision = eval_metrics(y_test, y_pred)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average= 'weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average= 'weighted')\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision })\n",
    "\n",
    "        signature = mlflow.models.infer_signature(X_train, lr.predict(X_train))\n",
    "    \n",
    "        print(f\"  recall:  {recall}\")\n",
    "        print(f\"  f1: {f1}\")\n",
    "        print(f\"  accuracy:  {accuracy}\") \n",
    "        print(f\"  precision:  {precision}\")\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Logging/autologging\n",
    "\n",
    "## Parameters explained:\n",
    "Parameter:\tDescription\n",
    "\n",
    "sk_model:\tThe trained sklearn model you want to save (e.g. LogisticRegression())\n",
    "\n",
    "artifact_path:\tThe path inside the run's artifact store to save the model (\"model\" is typical)\n",
    "\n",
    "registered_model_name:\t(Optional) If you want to register the model to MLflow Model Registry, give a name here\n",
    "\n",
    "signature:\t(Optional) Schema of inputs/outputs ‚Äî helps validate during serving (use mlflow.models.infer_signature())\n",
    "\n",
    "input_example:\t(Optional) A sample input ‚Äî helps document and validate how to call the model\n",
    "\n",
    "conda_env or pip_requirements:\t(Optional) Specify dependencies, but usually MLflow handles this automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'tracking_iris' already exists. Creating a new version of this model...\n",
      "2025/04/07 19:55:12 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: tracking_iris, version 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bouncy-asp-355 at: http://127.0.0.1:8080/#/experiments/228836478271870438/runs/302e3d2620dc47339a3188be9e7106ab\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/228836478271870438\n",
      "inputs: \n",
      "  ['sepal length (cm)': double (required), 'sepal width (cm)': double (required), 'petal length (cm)': double (required), 'petal width (cm)': double (required)]\n",
      "outputs: \n",
      "  [Tensor('int64', (-1,))]\n",
      "params: \n",
      "  None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '8' of model 'tracking_iris'.\n"
     ]
    }
   ],
   "source": [
    "model_info = mlflow.sklearn.log_model(\n",
    "    sk_model=lr,\n",
    "    signature= signature,\n",
    "    artifact_path='MLflow_iris',\n",
    "    input_example=X_train,\n",
    "    registered_model_name='tracking_iris'\n",
    ")\n",
    "\n",
    "mlflow.log_params(params)\n",
    "mlflow.log_metrics({\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision })\n",
    "\n",
    "## registers model info in model artifacts.\n",
    "\n",
    "\n",
    "if mlflow.active_run():\n",
    "       mlflow.end_run()\n",
    "       \n",
    "print(model_info.signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f08da9135e427d87916c56c58177fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>actual_class</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  ...  actual_class  predicted_class\n",
       "73                6.1               2.8  ...             1                1\n",
       "18                5.7               3.8  ...             0                0\n",
       "\n",
       "[2 rows x 6 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Load the model as a Python Function (pyfunc) and use it for inference\n",
    "\n",
    "loaded_model= mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "\n",
    "iris_feature_names = iris.feature_names\n",
    "\n",
    "result = pd.DataFrame(X_test, columns=iris_feature_names)\n",
    "result[\"actual_class\"] = y_test\n",
    "result[\"predicted_class\"] = predictions\n",
    "\n",
    "result[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "mlflow-artifacts:/228836478271870438/f7912e51367c48c2b4594b35d27c80f9/artifacts\n"
     ]
    }
   ],
   "source": [
    "run = mlflow.get_run(\"f7912e51367c48c2b4594b35d27c80f9\")\n",
    "print(run.data.params)\n",
    "print(run.data.metrics)\n",
    "print(run.info.artifact_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens under the hood\n",
    "\n",
    "MLflow:\n",
    "\n",
    "1.Serializes the model (usually with cloudpickle)\n",
    "\n",
    "\n",
    "2. Stores it in the run‚Äôs artifacts/ folder (e.g. under artifacts/model/)\n",
    "\n",
    "\n",
    "3. Saves a MLmodel file that contains metadata, including:\n",
    "\n",
    "    a.  What loader to use (python_function)\n",
    "\n",
    "\n",
    "    b.  What environment the model needs\n",
    "\n",
    "\n",
    "    c.  Signature and input example (if given)\n",
    "    \n",
    "\n",
    "    d.   Optionally, adds the model to the Model Registry (if registered_model_name is given)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow artifacts\n",
    "\n",
    "mlruns/\n",
    "‚îú‚îÄ‚îÄ <experiment_id>/\n",
    "\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ <run_id>/\n",
    "\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ artifacts/\n",
    "\n",
    "‚îÇ           ‚îú‚îÄ‚îÄ model.pkl/\n",
    "\n",
    "‚îÇ           ‚îú‚îÄ‚îÄ confusion_matrix.png\n",
    "\n",
    "\n",
    "‚îÇ           ‚îî‚îÄ‚îÄ transformed_data.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to Log Artifacts (code)-- don't run\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Create a sample CSV\n",
    "    df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "    df.to_csv(\"sample_data.csv\", index=False)\n",
    "    \n",
    "    # Log as artifact\n",
    "    mlflow.log_artifact(\"sample_data.csv\")\n",
    "\n",
    "# This will upload sample_data.csv to the run's artifact folder\n",
    "\n",
    "\n",
    "# Log a file under a subdirectory\n",
    "\n",
    "mlflow.log_artifact(\"sample_data.csv\", artifact_path=\"data\")\n",
    "\n",
    "\n",
    "# Log an entire folder\n",
    "\n",
    "import os\n",
    "\n",
    "# Create a directory with multiple files\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "with open(\"outputs/info.txt\", \"w\") as f:\n",
    "    f.write(\"This is some metadata.\")\n",
    "\n",
    "mlflow.log_artifacts(\"outputs\")  # Notice the plural: log_artifacts()\n",
    "\n",
    "\n",
    "#  Log images, like plots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([1, 2, 3], [4, 5, 6])\n",
    "plt.title(\"Simple Plot\")\n",
    "plt.savefig(\"plot.png\")\n",
    "mlflow.log_artifact(\"plot.png\", artifact_path=\"plots\")\n",
    "\n",
    "\n",
    "#  How to Retrieve Artifacts Later\n",
    "\n",
    "run_id = mlflow.active_run().info.run_id\n",
    "local_path = mlflow.artifacts.download_artifacts(run_id=run_id, path=\"data/sample_data.csv\")\n",
    "print(\"Downloaded to:\", local_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow model signature\n",
    "\n",
    "Summary\n",
    "\n",
    "Feature\tDescription\n",
    "\n",
    "‚úÖ What\tSchema of input/output for the model\n",
    "\n",
    "üìç How\tUse infer_signature() or define manually\n",
    "\n",
    "üîí Why\tHelps with validation, deployment, documentation\n",
    "\n",
    "üöÄ Where\tPassed in log_model(), saved in MLmodel file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
