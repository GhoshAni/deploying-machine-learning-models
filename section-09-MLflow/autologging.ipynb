{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Logging with MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types import Schema, ColSpec\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0 --port 5000\n",
    "\n",
    "--backend-store-uri sqlite:///mlflow.db: Stores runs in a SQLite database.\n",
    "\n",
    "--default-artifact-root ./mlruns: Stores models and artifacts in mlruns/.\n",
    "\n",
    "--host 0.0.0.0 --port 8080: Allows remote access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/27 20:45:58 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'f5e3472c424b4be8a1474976c9fca8c5', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run casual-steed-515 at: http://127.0.0.1:8080/#/experiments/517851688068192192/runs/f5e3472c424b4be8a1474976c9fca8c5\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/517851688068192192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable auto logging\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)  # Convert to DataFrame\n",
    "y = iris.target  # Labels\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run youthful-stoat-230 at: http://127.0.0.1:8080/#/experiments/517851688068192192/runs/889f9994355e44448589c642286c2e4e\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/517851688068192192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define input schema (with feature names and types)\n",
    "input_schema = Schema([\n",
    "    ColSpec(\"float\", col) for col in X.columns  # All input features are floats\n",
    "])\n",
    "\n",
    "# Define output schema (Logistic Regression predicts class labels: integer)\n",
    "output_schema = Schema([ColSpec(\"integer\", \"predicted_class\")])\n",
    "\n",
    "# Create custom signature\n",
    "custom_signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "\n",
    "\n",
    "# set mlflow tracking url\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "mlflow.set_experiment('mlflow_demo_diabetes')\n",
    "\n",
    "# Define model parameters and metrics\n",
    "params = {\"solver\": \"lbfgs\", \"C\": 1.0}\n",
    "metrics = {\"train_accuracy\": lr.score(X_train_scaled, y_train), \"test_accuracy\": lr.score(X_test_scaled, y_test)}\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(params)   # Log hyperparameters\n",
    "    mlflow.log_metrics(metrics)  # Log model performance\n",
    "    mlflow.set_tag(\"model_type\", \"Logistic Regression\")  # Set a tag\n",
    "    mlflow.sklearn.log_model( # Log the model with the custom signature\n",
    "   sk_model=lr,\n",
    "   artifact_path=\"iris_lr_model\",\n",
    "   signature=custom_signature,  # Custom schema\n",
    "   input_example=X_train[:5]    # Example input data\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow params , metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged Parameters: {'solver': 'lbfgs', 'C': '1.0'}\n",
      "logged Metrics {'train_accuracy': 0.9666666666666667, 'test_accuracy': 1.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load latest run details\n",
    "experiment_id = mlflow.get_experiment_by_name(\"mlflow_demo_diabetes\").experiment_id\n",
    "run = mlflow.search_runs(experiment_ids=experiment_id).iloc[0]\n",
    "\n",
    "if experiment_id :\n",
    "    runs = mlflow.search_runs(experiment_id)\n",
    "    if not runs.empty:\n",
    "        run_id = run.iloc[0]\n",
    "        logged_params = mlflow.get_run(run_id).data.params\n",
    "        metrics = mlflow.get_run(run_id).data.metrics\n",
    "        print(\"Logged Parameters:\", logged_params)\n",
    "        print(\"logged Metrics\", metrics)\n",
    "    else:\n",
    "        print(\"No runs Found\")\n",
    "else:\n",
    "    print('No experiment found')   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
